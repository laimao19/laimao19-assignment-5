{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6v6m-W8kb-J5"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjqQs8iob-J6"
      },
      "outputs": [],
      "source": [
        "# Define the KNN class\n",
        "class KNN:\n",
        "    def __init__(self, k=3, distance_metric='euclidean'):\n",
        "        self.k = k\n",
        "        self.distance_metric = distance_metric\n",
        "        self.X_train = None\n",
        "        self.y_train = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.X_train = X\n",
        "        self.y_train = y\n",
        "\n",
        "    def predict(self, X):\n",
        "        predictions = []\n",
        "        for i in range(X.shape[0]):\n",
        "            distances = [self.compute_distance(X[i], x_train) for x_train in self.X_train]\n",
        "            k_nearest_indices = np.argsort(distances)[:self.k]\n",
        "            k_nearest_labels = [self.y_train[idx] for idx in k_nearest_indices]\n",
        "            prob_class_1 = sum(k_nearest_labels) / self.k\n",
        "            predictions.append(prob_class_1)\n",
        "        return np.array(predictions)\n",
        "\n",
        "    def compute_distance(self, X1, X2):\n",
        "         if self.distance_metric == 'euclidean':\n",
        "            return np.sqrt(np.sum((X1 - X2) ** 2))\n",
        "\n",
        "         elif self.distance_metric == 'manhattan':\n",
        "            return np.sum(np.abs(X1 - X2))\n",
        "\n",
        "         elif self.distance_metric == 'cosine':\n",
        "            dot_product = np.dot(X1, X2)\n",
        "            norm_X1 = np.linalg.norm(X1)\n",
        "            norm_X2 = np.linalg.norm(X2)\n",
        "            return 1 - dot_product / (norm_X1 * norm_X2)\n",
        "\n",
        "         elif self.distance_metric == 'chebyshev':\n",
        "            return np.max(np.abs(X1 - X2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLDM5w0nb-J6"
      },
      "outputs": [],
      "source": [
        "def preprocess_data(train_path, test_path):\n",
        "    # Load the train and test datasets\n",
        "    train_data = pd.read_csv(train_path)\n",
        "    test_data = pd.read_csv(test_path)\n",
        "\n",
        "    # Handle missing values by filling them with the mean of the column\n",
        "    # Only for numeric features\n",
        "    numeric_features = ['CreditScore', 'Age', 'Tenure', 'Balance', 'NumOfProducts', 'EstimatedSalary']\n",
        "    for feature in numeric_features:\n",
        "        train_data[feature] = train_data[feature].fillna(train_data[feature].mean())\n",
        "        test_data[feature] = test_data[feature].fillna(test_data[feature].mean())\n",
        "\n",
        "    # Encode the 'Gender' column manually (0 for Female, 1 for Male)\n",
        "    train_data['Gender'] = train_data['Gender'].apply(lambda x: 1 if x == 'Male' else 0)\n",
        "    test_data['Gender'] = test_data['Gender'].apply(lambda x: 1 if x == 'Male' else 0)\n",
        "\n",
        "    # One-hot encode the 'Geography' column manually\n",
        "    for country in ['France', 'Germany']:\n",
        "        train_data[f'Geography_{country}'] = (train_data['Geography'] == country).astype(int)\n",
        "        test_data[f'Geography_{country}'] = (test_data['Geography'] == country).astype(int)\n",
        "\n",
        "    # Scale the numerical features manually\n",
        "    for feature in numeric_features:\n",
        "        mean = train_data[feature].mean()\n",
        "        std = train_data[feature].std()\n",
        "\n",
        "        # Standardize by mean and std deviation for both train and test sets\n",
        "        train_data[feature] = (train_data[feature] - mean) / std\n",
        "        test_data[feature] = (test_data[feature] - mean) / std  # Use training mean and std\n",
        "\n",
        "    # Separate the features and target variable for the training set\n",
        "    X_train = train_data.drop(['CustomerId', 'Surname', 'Exited', 'Geography'], axis=1)\n",
        "    y_train = train_data['Exited']\n",
        "\n",
        "    # Prepare the test set features\n",
        "    X_test = test_data.drop(['CustomerId', 'Surname', 'Geography'], axis=1)\n",
        "\n",
        "    return X_train.values, y_train.values, X_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xda8w11Db-J7"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def cross_validate(X, y, knn, n_splits=5):\n",
        "    \"\"\"Performs cross-validation and computes ROC AUC scores without sklearn.\"\"\"\n",
        "\n",
        "    # Shuffle the data\n",
        "    indices = np.arange(X.shape[0])\n",
        "    np.random.shuffle(indices)\n",
        "    X, y = X[indices], y[indices]\n",
        "\n",
        "    # Determine fold size and initialize the list for storing AUC scores\n",
        "    fold_size = X.shape[0] // n_splits\n",
        "    roc_auc_scores = []\n",
        "\n",
        "    for i in range(n_splits):\n",
        "        # Define the start and end of the validation fold\n",
        "        start, end = i * fold_size, (i + 1) * fold_size\n",
        "        X_val, y_val = X[start:end], y[start:end]\n",
        "        X_train = np.concatenate((X[:start], X[end:]), axis=0)\n",
        "        y_train = np.concatenate((y[:start], y[end:]), axis=0)\n",
        "\n",
        "        # Fit the KNN model on the training data\n",
        "        knn.fit(X_train, y_train)\n",
        "\n",
        "        # Get probability scores for the validation set\n",
        "        y_val_pred = []\n",
        "        for x in X_val:\n",
        "            # Calculate distances and find the k nearest neighbors\n",
        "            distances = [knn.compute_distance(x, x_train) for x_train in knn.X_train]\n",
        "            k_nearest_indices = np.argsort(distances)[:knn.k]\n",
        "            k_nearest_labels = [knn.y_train[idx] for idx in k_nearest_indices]\n",
        "\n",
        "            # Calculate the probability of class 1 (label == 1) based on neighbor votes\n",
        "            prob_class_1 = sum(k_nearest_labels) / knn.k\n",
        "            y_val_pred.append(prob_class_1)\n",
        "\n",
        "        # Convert to numpy array for easier handling\n",
        "        y_val_pred = np.array(y_val_pred)\n",
        "\n",
        "        # Sort the predictions and corresponding true labels in descending order\n",
        "        desc_sorted_indices = np.argsort(-y_val_pred)\n",
        "        y_val_sorted = y_val[desc_sorted_indices]\n",
        "        y_scores_sorted = y_val_pred[desc_sorted_indices]\n",
        "\n",
        "        # Total positives and negatives\n",
        "        P = np.sum(y_val == 1)\n",
        "        N = np.sum(y_val == 0)\n",
        "\n",
        "        # Initialize TPR and FPR lists\n",
        "        TPR = []\n",
        "        FPR = []\n",
        "\n",
        "        TP = 0\n",
        "        FP = 0\n",
        "\n",
        "        # Iterate through sorted scores\n",
        "        for j in range(len(y_scores_sorted)):\n",
        "            if y_val_sorted[j] == 1:\n",
        "                TP += 1\n",
        "            else:\n",
        "                FP += 1\n",
        "\n",
        "            tpr = TP / P if P > 0 else 0\n",
        "            fpr = FP / N if N > 0 else 0\n",
        "\n",
        "            TPR.append(tpr)\n",
        "            FPR.append(fpr)\n",
        "\n",
        "        #append (0,0) at the beginning and (1,1) at the end to complete the ROC curve\n",
        "        TPR = [0] + TPR + [1]\n",
        "        FPR = [0] + FPR + [1]\n",
        "\n",
        "        #calculate AUC using the trapezoidal rule\n",
        "        auc_score = 0.0\n",
        "        for j in range(1, len(FPR)):\n",
        "            auc_score += (FPR[j] - FPR[j-1]) * (TPR[j] + TPR[j-1]) / 2.0\n",
        "        roc_auc_scores.append(auc_score)\n",
        "\n",
        "    #return the mean ROC AUC score across all folds\n",
        "    return np.mean(roc_auc_scores)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "usllWdn6b-J7",
        "outputId": "19cecf6a-8094-4487-f7cb-4edb5f5ea3c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-validation scores: 0.5371374182231293\n",
            "k=9, metric=euclidean, AUC score=0.526014694263458\n",
            "k=9, metric=manhattan, AUC score=0.6194072025732258\n",
            "k=9, metric=cosine, AUC score=0.8936885572428022\n",
            "k=9, metric=chebyshev, AUC score=0.5049145179451052\n",
            "k=15, metric=euclidean, AUC score=0.5095510115020485\n",
            "k=15, metric=manhattan, AUC score=0.597336589398805\n",
            "k=15, metric=cosine, AUC score=0.9024629991158475\n",
            "k=15, metric=chebyshev, AUC score=0.499951917237452\n",
            "Best parameters: k=15, metric=cosine, AUC score=0.9024629991158475\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess data\n",
        "X, y, X_test = preprocess_data('/content/train.csv', '/content/test.csv')\n",
        "\n",
        "# Create and evaluate model\n",
        "knn = KNN(k=5, distance_metric='euclidean')\n",
        "\n",
        "# Perform cross-validation\n",
        "cv_scores = cross_validate(X, y, knn)\n",
        "\n",
        "print(\"Cross-validation scores:\", cv_scores)\n",
        "\n",
        "# hyperparamters tuning\n",
        "best_k = None\n",
        "best_distance_metric = None\n",
        "best_auc_score = -1\n",
        "for k in [9, 15]:  #range between 9 and 15 because i tested 3, 5, 7, 9, 11, 13, 15 before and 15 performed the best and 9 was just a random number\n",
        "    for metric in ['euclidean', 'manhattan', 'cosine', 'chebyshev']:\n",
        "        knn = KNN(k=k, distance_metric=metric)\n",
        "        auc_score = cross_validate(X, y, knn)\n",
        "        print(f\"k={k}, metric={metric}, AUC score={auc_score}\")\n",
        "\n",
        "        # Update best parameters based on AUC score\n",
        "        if auc_score > best_auc_score:\n",
        "            best_k = k\n",
        "            best_distance_metric = metric\n",
        "            best_auc_score = auc_score\n",
        "\n",
        "print(f\"Best parameters: k={best_k}, metric={best_distance_metric}, AUC score={best_auc_score}\")\n",
        "\n",
        "# TODO: Train on full dataset with optimal hyperparameters and make predictions on test set\n",
        "knn = KNN(k=best_k, distance_metric=best_distance_metric)\n",
        "knn.fit(X, y)\n",
        "test_predictions = knn.predict(X_test)\n",
        "\n",
        "# Save test predictions\n",
        "pd.DataFrame({'id': pd.read_csv('/content/test.csv')['id'], 'Exited': test_predictions}).to_csv('submissions.csv', index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.15"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}